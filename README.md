# What-can-A-I-see
AI tool to assist visually impaired people. It takes a voice prompt and an image, and generates and audio description of the image considering the user prompt

Our project aims to provide an assistive technology tool to support visually impaired people, providing them with a description of the scene they are in. This project would integrate image description, speech-to-text, and voice synthesis models. Provided an image and a voice prompt, the model generates a description considering the user's prompt, and it outputs the description as audio. The goal of our technology is to use deep learning techniques in order to improve daily life quality and increase the autonomy of sight-impaired people.
